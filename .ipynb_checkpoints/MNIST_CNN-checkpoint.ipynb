{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/mnist/pros/\n",
    "\n",
    "TF依赖高效的C++后端（backend）来进行计算。和backend的连接被称作session。TF的使用通常是先创建图，然后在一个session中启动它。\n",
    "使用tf.InteractiveSession()可以交互地创建operation运行图，也就是说不用完全构建出完整的computation graph就可以开始一个session，启动图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "    # tf.Variable是图中的一个tensor，可以理解为图中的一种参数类型\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2D convolution  \n",
    "tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, data_format=None, name=None)  \n",
    "strides: 1-D of size 4. The stride of the sliding window for each dimension of input.\n",
    "\n",
    "inpur tensor的shape [batch, in_height, in_width, in_channels]  \n",
    "filter tensor的shape [filter_height, filter_width, in_channels, out_channels]  \n",
    "\n",
    "conv2d的处理过程   \n",
    "1.将filter flatten成2-D矩阵， shape [filter_height \\* filter_width \\* in_channels, output_channels]  \n",
    "2.从输入tensor中提取image patches，构成虚拟tensor， shape [batch, out_height, out_width, filter_height \\* filter_width \\* in_channels]  \n",
    "3.对于每一个patch， 右乘filter matrix和image patch vector  \n",
    "\n",
    "In NHWC format （default）：  \n",
    "$output[b, i, j, k] = sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q] *                   filter[di, dj, q, k]$  \n",
    "必须有strides[0]=strides[3]=1， strides = [1, stride, stride, 1],通常水平和垂直的stride一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Abstract the conlution and pooing operations into  functions\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype=tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(dtype=tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# layer 1\n",
    "W_conv1 = weight_variable([5, 5, 1, 32]) # [path_height, patch_width, in_channels, out_channels]\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "# 我们需要对将x reshape成4D tensor。中间两维对应图片height和width，最后一维对应color channels\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# layer 2\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "# fc layer\n",
    "W_fc3 = weight_variable([7*7*64, 1024])\n",
    "b_fc3 = bias_variable([1024])\n",
    "\n",
    "h_flat3 = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc3 = tf.nn.relu(tf.matmul(h_flat3, W_fc3) + b_fc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 加入dropout科技，防止过拟合,一般加在全连接层。 卷积层用于提取特征\n",
    "keep_prob = tf.placeholder(tf.float32) # 训练时使用dropout，测试时关闭\n",
    "# tf.nn.dropout操作可以自动地缩放神经元的输出，达到mask的目的\n",
    "h_fc3_dropout = tf.nn.dropout(h_fc3, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc4 = weight_variable([1024, 10])\n",
    "b_fc4 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc3_dropout, W_fc4) + b_fc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.078125\n",
      "step 100, training accuracy 0.859375\n",
      "step 200, training accuracy 0.90625\n",
      "step 300, training accuracy 0.953125\n",
      "step 400, training accuracy 0.953125\n",
      "step 500, training accuracy 0.96875\n",
      "step 600, training accuracy 0.921875\n",
      "step 700, training accuracy 0.96875\n",
      "step 800, training accuracy 0.96875\n",
      "step 900, training accuracy 0.953125\n",
      "test accuracy 0.967\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-4\n",
    "training_steps =  1000\n",
    "batch_size = 64\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_conv, y_))\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_, axis=1)) # 得到bool向量\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(training_steps):\n",
    "    batch = mnist.train.next_batch(batch_size)\n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict = {x: batch[0], y_:batch[1], keep_prob: 1.0})\n",
    "        # eval 执行一个operation\n",
    "        print(\"step %d, training accuracy %g\" % (i, train_accuracy))\n",
    "    train_step.run(feed_dict = {x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "print(\"test accuracy %g\" % accuracy.eval(feed_dict = {x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
